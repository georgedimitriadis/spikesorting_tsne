"""
Set of functions that allow the t-sne algorithm to use the result of the kilosort automatic spike clustering algorithm.
The functions assume file names in the base_folder (the folder that kilosort puts its results in) as generated by
kilosort.

Some functions from this collection are also useful together with the GUI that allows cleaning of the kilosort templates
and the GUI that allows manual curation of the kilosort results using the t-sne embedding (e.g. generate_spike_info)
"""


import numpy as np
from os import path
import pickle
import pandas as pd
from . import io_with_cpp as io
from . import constants as ct
from . import tsne
import os
import sys
import copy


# -----------------------------------------------------------------
# FUNCTIONS FOR PREPROCESSING KILOSORT LIKE ARRAYS TO GIVE TO T-SNE
def spike_indices_of_template(spike_templates, clean_templates=None, clean_template_index=None):
    """
    Returns the indices of the spikes belonging to a template from the group of clean templates (after manual cleaning
    of the kilosort results). The manual cleaning results are pulled from the template_markings.npy file saved the
    cleaning GUI in the same folder as the kilosort results

    :param spike_templates: The vector in the spike_templates.npy file of the kilosort results
    :type spike_templates: int[:]
    :param clean_templates: The vector of indices in the vector of the original templates of the templates that are
    clean. E.g. If originally templates [1,2,4,5,13,22,23] where found but templates 2 and 13 where noise then
    clean_templates = [0,2,3,4,6,7]

    :type clean_templates: int[:]
    :param clean_template_index: The index in the vector of the clean_templates of the template whose spikes we need
    :type clean_template_index: int
    :return: a vector of the indices of spikes belonging to the template
    :rtype: int[:]
    """
    if clean_templates is None:
        original_template_index = spike_templates
    else:
        original_template_index = clean_templates[clean_template_index]
    spikes_indices = np.squeeze(np.argwhere(np.in1d(spike_templates, original_template_index)))
    return spikes_indices


def find_templates_with_number_of_spikes_under_threshold(spike_templates, clean_templates, threshold):
    """
    Finds all the templates that have fewer number of spikes than a given threshold

    :param spike_templates: the original spike_templates as generated by kilosort
    :type spike_templates: int[:]
    :param clean_templates: the vector of which template each spike is assigned to but only for the clean templates
    :type clean_templates: int[:]
    :param threshold: the number of spikes allowed in a chosen template
    :type threshold: int
    :return: a dictionary with keys the templates with fewer than threshold spikes (small templates) and values their
    spike indices, the total number of spikes in these small templates, a dictionary with keys the remaining (large)
    templates and values the indices of their spikes

    :rtype: dict, int , dict
    """
    small_clean_templates_with_indices = dict()
    large_clean_templates_with_indices = dict()
    num_of_spikes_in_small_templates = 0
    for i in np.arange(len(clean_templates)):
        spike_indices = spike_indices_of_template(spike_templates, clean_templates, i)
        num_of_spikes = spike_indices.size
        if num_of_spikes <= threshold:
            small_clean_templates_with_indices[i] = spike_indices
            num_of_spikes_in_small_templates += num_of_spikes
        else:
            large_clean_templates_with_indices[i] = spike_indices

    return small_clean_templates_with_indices, num_of_spikes_in_small_templates, large_clean_templates_with_indices


def get_template_marking(base_folder):
    """
    Returns the template_marking vector (if a manual curation session has been performed on the kilosort results) which
    assigns to each template one of 7 possibilities. Since 0 means noise and all other possibilities are positive
    numbers this vector can act as a mask to exclude spikes of templates that have been marked as noise.
    If no template_markings.npy file is found then the function returns a vector of ones as long as the spike_templates
    vector

    :param base_folder: the folder with the kilosort results
    :type base_folder: string
    :return: vector of markings for each spike according to the type its template has been manually assigned to
    :rtype: int[:]
    """

    if path.isfile(path.join(base_folder, ct.TEMPLATE_MARKING_FILENAME)):
        template_marking = np.load(path.join(base_folder, ct.TEMPLATE_MARKING_FILENAME))
    else:
        templates = np.load(path.join(base_folder, ct.TEMPLATES_FILENAME))
        num_of_templates = templates.shape[2]
        template_marking = np.ones(num_of_templates)
        del templates
        print('No template_marking.npy found. Using all templates.')

    return template_marking


def find_spike_indices_for_representative_tsne(base_folder, save_to_folder, threshold, total_spikes_required):
    """
    The function is used to create a subset of spikes using the following criteria. 1) The total number of spikes in the
    subset has to be smaller than the total_spikes_required value. 2) All spikes belonging to templates with threshold
    or fewer number of spikes should be included. If the threshold is too big and the total_spikes_required too small
    a number then these might not be mutually achievable criteria. If this is not the case then all the spikes belonging
    to templates with fewer than threshold spikes will be included. That will give a total of spikes smaller than the
    total_spikes_required value. The difference between the total_spikes_required and the total spikes in the small
    templates will be filled by spikes from the remaining large templates (the ones with higher number of spikes than
    threshold). The algorithm will calculate how many spikes these large templates have and use this to calculate a
    percentage of spikes for each large template that will bring the number of spikes in the subset equal to the
    total_spikes_required value. In this way the subset will be a full representation of the small templates (which
    will be the large majority of templates) and a random representation of part of the larger templates (which will be
    the small minority). Each large spike will contribute a specific percentage of its own total spikes.

    This technique can be used to create subsets of spikes whose total number of spikes does not exceed the t-sne
    capabilities. Use the indices_of_spikes_used returned vector to pass to the spikes_used_with_clean_indexing
    parameter of the calculate_template_features_matrix_for_tsne function.
    After running t-sne on this set any large templates that are still of interest (have not been
    delegated to noise and after any merging and splitting) can be run by themselves on a separate t-sne.

    :param base_fofder: the folder with the kilosort results
    :type base_folder: string
    :param save_to_folder: the function except returning the results will also save them as files to this folder. It
    also save dictionaries that make searching through the small and large templates easier

    :type save_to_folder: string
    :param threshold: the number of spikes that full included templated must be under
    :type threshold: int
    :param total_spikes_required: the total number of spikes in the resulting subset
    :type total_spikes_required: int
    :return: a vector with the indices of all the spikes in the subset,
    a dictionary with keys the small templates and values their spike indices,
    a dictionary with keys the large templates and values their spike indices

    :rtype: int[:], dict, dict
    """
    spike_templates = np.load(path.join(base_folder, ct.SPIKE_TEMPLATES_FILENAME))
    template_marking = get_template_marking(base_folder)

    clean_templates = np.argwhere(template_marking)

    small_clean_templates_with_spike_indices, num_of_spikes_in_small_templates, large_clean_templates_with_spike_indices = \
        find_templates_with_number_of_spikes_under_threshold(spike_templates, clean_templates, threshold)

    extra_spikes_required = total_spikes_required - num_of_spikes_in_small_templates

    spikes_clean_index = np.squeeze(np.argwhere(np.in1d(spike_templates, clean_templates)))
    percentage_of_kept_spikes_in_large_templates = extra_spikes_required / (spikes_clean_index.size -
                                                                            num_of_spikes_in_small_templates)

    spikes_chosen = []
    num_of_spikes_in_large_templates = 0
    for large_template_index in large_clean_templates_with_spike_indices.keys():
        spike_indices = large_clean_templates_with_spike_indices[large_template_index]
        num_of_spikes = spike_indices.size
        num_of_spikes_in_large_templates += num_of_spikes
        chosen_num_of_spikes = int(num_of_spikes * percentage_of_kept_spikes_in_large_templates)
        chosen_spike_indices = np.random.choice(spike_indices, chosen_num_of_spikes, replace=False)
        spikes_chosen.append(chosen_spike_indices)

    num_of_spikes_in_small_templates = 0
    for small_template_index in small_clean_templates_with_spike_indices.keys():
        spike_indices = small_clean_templates_with_spike_indices[small_template_index]
        spikes_chosen.append(spike_indices)
        num_of_spikes_in_small_templates += spike_indices.size

    print('{} templates with more than {} spikes (total spikes in those = {}). \n{} templates with less '
          'than {} spikes (total spikes in those = {}). \npercentage of spikes in the large templates = '
          '{}%'.format(len(large_clean_templates_with_spike_indices),
               threshold, num_of_spikes_in_large_templates,
               len(small_clean_templates_with_spike_indices),
               threshold, num_of_spikes_in_small_templates,
               percentage_of_kept_spikes_in_large_templates * 100))

    spikes_chosen_flat = []
    for sublist in spikes_chosen:
        if np.size(sublist) > 1:
            for item in sublist:
                spikes_chosen_flat.append(item)
        else:
            spikes_chosen_flat.append(sublist)

    indices_of_spikes_used = np.array(spikes_chosen_flat)
    small_clean_templates_indices = np.fromiter(small_clean_templates_with_spike_indices.keys(), int,
                                                len(small_clean_templates_with_spike_indices))
    large_clean_tempalates_indices = np.fromiter(large_clean_templates_with_spike_indices.keys(), int,
                                                 len(large_clean_templates_with_spike_indices))
    pickle.dump(small_clean_templates_with_spike_indices,
                open(path.join(save_to_folder, ct.SMALL_CLEAN_TEMPLATES_WITH_SPIKE_INDICES_PICKLE), "wb"))
    pickle.dump(large_clean_templates_with_spike_indices,
                open(path.join(save_to_folder, ct.LARGE_CLEAN_TEMPLATES_WITH_SPIKE_INDICES_PICKLE), "wb"))
    np.save(path.join(save_to_folder, ct.INDICES_OF_SPIKES_USED_FILENAME), indices_of_spikes_used)
    np.save(path.join(save_to_folder, ct.INDICES_OF_SMALL_TEMPLATES_FILENAME), small_clean_templates_indices)
    np.save(path.join(save_to_folder, ct.INDICES_OF_LARGE_TEMPLATES_FILENAME), large_clean_tempalates_indices)

    return indices_of_spikes_used, small_clean_templates_with_spike_indices, large_clean_templates_with_spike_indices


def calculate_template_features_matrix_for_tsne(base_folder, save_to_folder, spikes_used_with_original_indexing=None,
                                                spikes_used_with_clean_indexing=None):
    """
    Using the kilosort results, this function creates a matrix of samples x elements that can be used as an input to
    the t-sne algorithm. Each sample represents a spike and each element the distance of this spike to a specific
    template.

    :param base_folder: the folder where kilosort has saved its results
    :type base_folder: string
    :param save_to_folder: the folder to save the resulting .npy
    :type save_to_folder: string
    :param spikes_used_with_original_indexing: an array of indices to pick the spikes used. It uses the original spike
    indexing (as given by the kilosort results) before any cleaning

    :type spikes_used_with_original_indexing: int[:]
    :param spikes_used_with_clean_indexing: an array of indices to pick the spikes used. It uses the indexing after
    removing all spikes that are marked as noise by the cleaning process

    :type spikes_used_with_clean_indexing: int[:]
    :return: the spikes x template distances matrix to be used by the T-sne algorithm
    :rtype: float[:,:]
    """
    spike_templates = np.load(path.join(base_folder, ct.SPIKE_TEMPLATES_FILENAME))
    template_features = np.load(path.join(base_folder, ct.TEMPLATE_FEATURES_FILENAME))
    template_features_ind = np.load(path.join(base_folder, ct.TEMPLATE_FEATURES_INDEX_FILENAME))

    template_marking = get_template_marking(base_folder)

    clean_templates = np.squeeze(np.argwhere(template_marking))
    spikes_clean_index = np.squeeze(np.argwhere(np.in1d(spike_templates, clean_templates)))

    if spikes_used_with_original_indexing is not None and spikes_used_with_clean_indexing is not None:
        print('Use one of the spikes_used_... variable')
        return None
    elif spikes_used_with_original_indexing is None and spikes_used_with_clean_indexing is None:
        pass
    elif spikes_used_with_original_indexing is None and spikes_used_with_clean_indexing is not None:
        spikes_clean_index = spikes_clean_index[spikes_used_with_clean_indexing]
    elif spikes_used_with_original_indexing is not None and spikes_used_with_clean_indexing is None:
        spikes_clean_index = spikes_used_with_original_indexing

    spikes_clean_index = np.squeeze(spikes_clean_index)

    #clean_templates = np.unique(spike_templates[spikes_clean_index])

    template_features_sparse_clean = np.zeros((int(spikes_clean_index.size), int(clean_templates.size)))
    s = 0
    for spike in spikes_clean_index:
        spike = int(spike)
        cluster = np.squeeze(spike_templates[spike][0])
        indices = np.squeeze(template_features_ind[cluster, :])
        if s % 5000 == 0:
            print('Spikes completed: {}'.format(s))
        s += 1
        for i in np.arange(len(indices)):
            template_features_sparse_clean[np.squeeze(np.argwhere(spikes_clean_index == spike)),
                                           np.squeeze(np.argwhere(clean_templates == indices[i]))] = template_features[spike, i]

    np.save(path.join(save_to_folder, 'data_to_tsne_' + str(template_features_sparse_clean.shape) + '.npy'),
            template_features_sparse_clean)

    return template_features_sparse_clean


def calculate_pcs_features_matrix_for_tsne(base_folder, save_to_folder, spikes_used_with_original_indexing=None,
                                           spikes_used_with_clean_indexing=None):
    """
    Using the kilosort results, this function creates a matrix of samples x elements that can be used as an input to
    the t-sne algorithm. Each sample represents a spike and each element one of the 3 most important PCs of one of the
    mostt important channels.

    :param base_folder: the folder where kilosort has saved its results
    :type base_folder: string
    :param save_to_folder: the folder to save the resulting .npy
    :type save_to_folder: string
    :param spikes_used_with_original_indexing: an array of indices to pick the spikes used. It uses the original spike
    indexing (as given by the kilosort results) before any cleaning

    :type spikes_used_with_original_indexing: int[:]
    :param spikes_used_with_clean_indexing: an array of indices to pick the spikes used. It uses the indexing after
    removing all spikes that are marked as noise by the cleaning process

    :type spikes_used_with_clean_indexing: int[:]
    :return: the spikes x template distances matrix to be used by the T-sne algorithm
    :rtype: float[:,:]
    """
    spike_templates = np.load(path.join(base_folder, ct.SPIKE_TEMPLATES_FILENAME))

    pc_features = np.load(path.join(base_folder, 'pc_features.npy'))

    template_marking = get_template_marking(base_folder)

    clean_templates = np.squeeze(np.argwhere(template_marking))
    spikes_clean_index = np.squeeze(np.argwhere(np.in1d(spike_templates, clean_templates)))

    if spikes_used_with_original_indexing is not None and spikes_used_with_clean_indexing is not None:
        print('Use one of the spikes_used_... variable')
        return None
    elif spikes_used_with_original_indexing is None and spikes_used_with_clean_indexing is None:
        pass
    elif spikes_used_with_original_indexing is None and spikes_used_with_clean_indexing is not None:
        spikes_clean_index = spikes_clean_index[spikes_used_with_clean_indexing]
    elif spikes_used_with_original_indexing is not None and spikes_used_with_clean_indexing is None:
        spikes_clean_index = spikes_used_with_original_indexing

    spikes_clean_index = np.squeeze(spikes_clean_index)

    pc_features_matrix = np.zeros((spikes_clean_index.size, pc_features[0, :, :].size))
    s = 0
    for spike in spikes_clean_index:
        other = pc_features[spike, :, :].flatten()
        if s % 5000 == 0:
            print('Spikes completed: {}'.format(s))
        s += 1
        pc_features_matrix[np.squeeze(np.argwhere(spikes_clean_index == spike)), :] = other

    np.save(path.join(save_to_folder, 'data_to_tsne_' + str(pc_features_matrix.shape) + '.npy'),
            pc_features_matrix)

    return pc_features_matrix


def load_template_features_matrix_for_tsne(save_to_folder, shape):
    """
    Loads the npy array that carries the sparse matrix of spikes x distances to templates

    :param save_to_folder: the folder the matrix has been saved to
    :type save_to_folder: string
    :param shape: the shape of the matrix
    :type shape: tuple
    :return: the sparse matrix
    :rtype: float32[shape]
    """
    template_features_sparse_clean = np.load(path.join(save_to_folder, r'data_to_tsne_' + str(shape) + '.npy'))
    return template_features_sparse_clean
# -----------------------------------------------------------------


# -----------------------------------------------------------------
# FUNCTIONS TO READ AND MANIPULATE THE T-SNE RESULTS
def generate_spike_info_from_full_tsne(kilosort_folder, tsne_folder, tsne_filename='result.dat'):
    """
    spike_info.df is a pandas DataFrame that collates all the information about a group of spikes for sorting purposes.
    It is also the data frame that the GUI to manually curate kilosorted and t-sne data uses to load and save its
    results.

    :param kilosort_folder: the folder of the kilosort results
    :type kilosort_folder: string
    :param tsne_folder: the folder with the t-sne results
    :type tsne_folder: string
    :param tsne_filename: the filename of the t-sne results numpy array
    :type tsne_filename: string
    :return: saves and returns the spike_info dataframe
    :rtype: pandas.DataFrame
    """

    #if path.isfile(path.join(tsne_folder, tsne_filename)):
    tsne = io.load_tsne_result(tsne_folder, tsne_filename)
    #else:
    #    if path.isfile(path.join(kilosort_folder, ))

    partial_tsne = False

    if path.isfile(path.join(tsne_folder, ct.INDICES_OF_SPIKES_USED_FILENAME )):
        spikes_used = np.load(path.join(tsne_folder, ct.INDICES_OF_SPIKES_USED_FILENAME))
    else:
        spikes_used = np.arange(tsne.shape[0])

    spikes_used = spikes_used.astype(np.int32)

    if path.isfile(path.join(tsne_folder, ct.INDICES_OF_SMALL_TEMPLATES_FILENAME)) and partial_tsne:
        indices_of_small_templates = np.load(path.join(tsne_folder, ct.INDICES_OF_SMALL_TEMPLATES_FILENAME))
        partial_tsne = True
    else:
        indices_of_small_templates = spikes_used

    if path.isfile(path.join(tsne_folder, ct.WEIGHTED_TEMPLATE_POSITIONS_FILENAME)):
        weighted_template_positions = np.load(path.join(tsne_folder, ct.WEIGHTED_TEMPLATE_POSITIONS_FILENAME))
    else:
        weighted_template_positions = None

    if path.isfile(path.join(tsne_folder, ct.WEIGHTED_SPIKE_POSITIONS_FILENAME)):
        weighted_spike_positions = np.load(path.join(tsne_folder, ct.WEIGHTED_SPIKE_POSITIONS_FILENAME))
    else:
        weighted_spike_positions = None

    if path.isfile(path.join(kilosort_folder, ct.TEMPLATE_MARKING_FILENAME)):
        template_marking = np.load(path.join(kilosort_folder, ct.TEMPLATE_MARKING_FILENAME))
    else:
        template_marking = np.ones(tsne.shape[0]) * 5 # Set it to Unspecified_1

    spike_templates = np.squeeze(np.load(path.join(kilosort_folder, ct.SPIKE_TEMPLATES_FILENAME))[spikes_used])
    spike_times = np.squeeze(np.load(path.join(kilosort_folder, ct.SPIKE_TIMES_FILENAME))[spikes_used])

    columns = [ct.ORIGINAL_INDEX, ct.TIMES, ct.TEMPLATE_AFTER_CLEANING, ct.TYPE_AFTER_CLEANING, ct.TEMPLATE_AFTER_SORTING,
               ct.TYPE_AFTER_SORTING, ct.TEMPLATE_WITH_ALL_SPIKES_PRESENT, ct.TSNE_X, ct.TSNE_Y, ct.PROBE_POSITION_X,
               ct.PROBE_POSITION_Y]

    spike_info = pd.DataFrame(index=np.arange(spikes_used.size), columns=columns)

    spike_info[ct.ORIGINAL_INDEX] = spikes_used
    spike_info[ct.TIMES] = spike_times
    spike_info[ct.TEMPLATE_AFTER_CLEANING] = spike_templates
    spike_info[ct.TYPE_AFTER_CLEANING] = [ct.types[int(template_marking[i])] for i in spike_templates]
    spike_info[ct.TEMPLATE_AFTER_SORTING] = spike_info[ct.TEMPLATE_AFTER_CLEANING]
    spike_info[ct.TYPE_AFTER_SORTING] = spike_info[ct.TYPE_AFTER_CLEANING]
    if partial_tsne:
        spike_info[ct.TEMPLATE_WITH_ALL_SPIKES_PRESENT] = [bool(np.in1d(spike_template, indices_of_small_templates))
                                                          for spike_template in spike_templates]
    else:
        spike_info[ct.TEMPLATE_WITH_ALL_SPIKES_PRESENT] = [True for spike_template in spike_templates]

    if weighted_spike_positions is not None:
        spike_info[ct.PROBE_POSITION_X] = weighted_spike_positions[:, 0]
        spike_info[ct.PROBE_POSITION_Y] = weighted_spike_positions[:, 1]

    if weighted_spike_positions is None and weighted_template_positions is not None:
        spike_info[ct.PROBE_POSITION_X] = [weighted_template_positions[spike_template, 0]
                                          for spike_template in spike_templates]
        spike_info[ct.PROBE_POSITION_Y] = [weighted_template_positions[spike_template, 1]
                                          for spike_template in spike_templates]

    spike_info[ct.TSNE_X] = tsne[:, 0]
    spike_info[ct.TSNE_Y] = tsne[:, 1]

    spike_info.to_pickle(path.join(tsne_folder, ct.SPIKE_INFO_FILENAME))

    return spike_info


def reassign_all_spikes_after_partial_sorting_old(kilosort_folder, tsne_folder):
    spike_info = pd.read_pickle(path.join(tsne_folder, 'spike_info.df'))

    before_to_after_sorting_templates = dict()
    for index, spike in spike_info.iterrows():
        keys = before_to_after_sorting_templates.keys()
        if spike['template_after_cleaning'] not in keys:
            before_to_after_sorting_templates[spike['template_after_cleaning']] = spike['template_after_sorting']

    templates_of_spikes = np.load(path.join(kilosort_folder, 'spike_templates.npy'))
    template_markings = get_template_marking(kilosort_folder)
    clean_templates = np.argwhere(template_markings > 0)
    clean_spikes_indices = np.argwhere(np.in1d(templates_of_spikes, clean_templates) > 0)
    templates_of_clean_spikes = templates_of_spikes[clean_spikes_indices]
    sorted_spike_templates = []
    for template in templates_of_clean_spikes:
        sorted_spike_templates.append(before_to_after_sorting_templates[template[0][0]])

    sorted_spike_templates = np.squeeze(np.array(sorted_spike_templates))
    np.save(path.join(kilosort_folder, 'sorted_spike_templates.npy'), sorted_spike_templates)
    np.save(path.join(kilosort_folder, 'before_to_after_sorting_templates.npy'), before_to_after_sorting_templates)

    return sorted_spike_templates


def reassign_all_spikes_after_partial_sorting(kilosort_folder, tsne_folder):
    pass


def generate_spike_info_after_cleaning(kilosort_folder):
    """
    Given that the cleaning of the kilosort algorithm has resulted in the template_marking.npy, this function creates
    a spike_info dataframe with all the spikes assumed to be not noise (where template_marking > 0).
    This function assumes that no t-sne on any spikes had been performed yet, so it sets all the t-sne relevant columns
    to empty.

    The columns of the dataframe:

    original_index: The index of the spike in the original spike_templates or spike_times array (in the non cleaned,
     kilosort output)

    times: The time point of the spike

    template_after_cleaning: The template number right after the cleaning process (this is the same as the template
    number kilosort has assigned the spike since the cleaning process doesn't reassign spikes)

    type_after_cleaning: The type of the spike's temmplate (Single Unit, Contaminated, Putative, Multi Unit,
    Unclassified 1 to 3) after the cleaning process (which makes these assignments also

    template_after_sorting: After any type of sorting that results in the spike being reassigned its template, the new
    template is kept in this column. For this function this is the same as the template_after_cleaning.

    type_after_sorting: The type of the spike's new template (if sorting has reassigned it).

    template_with_all_spikes_present: If a t-sne was done that used part of the spikes of this template then this will
    be False, otherwise it will be True

    tsne_filename: The filename of the t-sne whose coordinates are used to fill the next two columns

    tsne_x: The x coordinate of the spike on the t-sne embedding

    tsne_y: The y coordinate of the spike on the t-sne embedding

    probe_position_x: The x position of the spike on the probe (thsi is calculated through the function
    spike_positioning_on_probe.generate_probe_positions_of_spikes)

    probe_position_z: The z position of the spike on the probe (thsi is calculated through the function
    spike_positioning_on_probe.generate_probe_positions_of_spikes)

    :param kilosort_folder: The folder where the kilosort results are
    :return: The spike_info dataframe
    """
    templates_of_spikes = np.squeeze(np.load(path.join(kilosort_folder, ct.SPIKE_TEMPLATES_FILENAME)))
    template_markings = get_template_marking(kilosort_folder)
    templates_used = np.argwhere(template_markings > 0)
    spikes_used = np.argwhere(templates_of_spikes == templates_used)

    spikes_used = np.squeeze(spikes_used.astype(np.int32)[:, 1])

    if path.isfile(path.join(kilosort_folder, ct.WEIGHTED_SPIKE_POSITIONS_FILENAME)):
        weighted_spike_positions = np.load(path.join(kilosort_folder, ct.WEIGHTED_SPIKE_POSITIONS_FILENAME))
    else:
        weighted_spike_positions = None

    try:
        template_marking = np.load(path.join(kilosort_folder, ct.TEMPLATE_MARKING_FILENAME))
    except FileExistsError:
        sys.exit('{} file must exist'.format(ct.TEMPLATE_MARKING_FILENAME))

    spike_templates = np.squeeze(np.load(path.join(kilosort_folder, ct.SPIKE_TEMPLATES_FILENAME))[spikes_used])
    spike_times = np.squeeze(np.load(path.join(kilosort_folder, ct.SPIKE_TIMES_FILENAME))[spikes_used])

    columns = [ct.ORIGINAL_INDEX, ct.TIMES, ct.TEMPLATE_AFTER_CLEANING, ct.TYPE_AFTER_CLEANING,
               ct.TEMPLATE_AFTER_SORTING, ct.TYPE_AFTER_SORTING, ct.TEMPLATE_WITH_ALL_SPIKES_PRESENT,
               ct.TSNE_FILENAME, ct.TSNE_X, ct.TSNE_Y, ct.PROBE_POSITION_X, ct.PROBE_POSITION_Y]

    spike_info = pd.DataFrame(index=np.arange(spikes_used.size), columns=columns)

    spike_info[ct.ORIGINAL_INDEX] = spikes_used
    spike_info[ct.TIMES] = spike_times
    spike_info[ct.TEMPLATE_AFTER_CLEANING] = spike_templates
    spike_info[ct.TYPE_AFTER_CLEANING] = [ct.types[int(template_marking[i])] for i in spike_templates]
    spike_info[ct.TEMPLATE_AFTER_SORTING] = spike_info[ct.TEMPLATE_AFTER_CLEANING]
    spike_info[ct.TYPE_AFTER_SORTING] = spike_info[ct.TYPE_AFTER_CLEANING]
    spike_info[ct.TEMPLATE_WITH_ALL_SPIKES_PRESENT] = True

    if weighted_spike_positions is not None:
        spike_info[ct.PROBE_POSITION_X] = weighted_spike_positions[:, 0]
        spike_info[ct.PROBE_POSITION_Y] = weighted_spike_positions[:, 1]

    spike_info.to_pickle(path.join(kilosort_folder, ct.SPIKE_INFO_AFTER_CLEANING_FILENAME))

    return spike_info


def add_sorting_info_to_spike_info(original_spike_info, sorted_spike_info, tsne_filename=None, save_to_file=None):
    """
    Adds the information in a spike_info dataframe that results after manual sorting (through a t-sne for example)
    into the main spike_info. The original_spike_info is the large spike info with all the clean spikes and the
    sorted_spike_info is the spike info df that has the new information to be added. It assumes that the sorted_spike_info
    is a subset of the original_spike_info, i.e. the sorted_spike_info has no spikes with a combination of time and
    template_after_cleaning values that do not exist in the original_spike_info.

    :param original_spike_info: The dataframe of spike info to be changed
    :param sorted_spike_info: The dataframe of spike info to add its info into the original_spike_info
    :param tsne_filename: If the sorted_spike_info has t-sne information then tell the function where the t-sne file that
    has that information is

    :param save_to_file: If not None save the result to this file name
    :return: The changed spike info
    """
    osi = copy.copy(original_spike_info)
    ssi = copy.copy(sorted_spike_info)

    osi = osi.set_index(ct.ORIGINAL_INDEX)
    ssi = ssi.set_index(ct.ORIGINAL_INDEX)

    osi[osi[ct.TIMES].isin(ssi[ct.TIMES]) & osi[ct.TEMPLATE_AFTER_CLEANING].isin(ssi[ct.TEMPLATE_AFTER_CLEANING])] = ssi

    osi[ct.ORIGINAL_INDEX] = osi.index
    osi.index = np.arange(len(osi))

    columns = osi.columns.tolist()
    columns = columns[-1:] + columns[:-1]

    osi = osi[columns]

    if tsne_filename is not None:
        osi[ct.TSNE_FILENAME][np.logical_not(osi[ct.TSNE_X].isnull())] = tsne_filename

    osi = osi[osi[ct.TYPE_AFTER_SORTING] != ct.types[0]]

    if save_to_file is not None:
        osi.to_pickle(save_to_file)

    return osi


def generate_template_info_after_cleaning(kilosort_folder, sampling_freq):
    """
    Given that the cleaning of the kilosort algorithm has resulted in the template_marking.npy, this function creates
    a template_info dataframe with all the clean (not noise) templates and their, spikes, types, number of spikes,
    firing rates and X and Y positions on the probe (if the spike_positioning_on_probe.generate_probe_positions_of_templates()
    has been run and there is a template_positions.npy file available)

    :param kilosort_folder: The folder where the kilosort results and the template_marking.npy files are
    :param sampling_freq: The sampling frequency of the raw data
    :return: The template_info dataframe
    """
    templates_of_spikes = np.squeeze(np.load(path.join(kilosort_folder, 'spike_templates.npy')))
    template_markings = get_template_marking(kilosort_folder)
    clean_templates = np.squeeze(np.argwhere(template_markings > 0))

    spike_times = np.load(path.join(kilosort_folder, 'spike_times.npy'))
    total_time = np.max(spike_times) / sampling_freq

    try:
        template_positions = np.load(path.join(kilosort_folder, 'weighted_template_positions.npy'))
    except:
        template_positions = np.zeros((len(clean_templates), 2))

    template_info = pd.DataFrame(columns=['template number', 'spikes in template', 'type', 'number of spikes',
                                          'firing rate', 'position X', 'position Y'])

    for clean_template_index in np.arange(len(clean_templates)):
        template_index = clean_templates[clean_template_index]
        type = template_markings[template_index]

        if type > 0:
            spikes_in_template = np.squeeze(np.argwhere(templates_of_spikes == template_index))
            number = len(spikes_in_template)
            rate = number / total_time

            template_info = template_info.append({'template number': template_index,
                                                 'spikes in template': spikes_in_template,
                                                  'type': type,
                                                  'number of spikes': number,
                                                  'firing rate': rate,
                                                  'position X': template_positions[clean_template_index, 0],
                                                  'position Y': template_positions[clean_template_index, 1]},
                                                 ignore_index=True)

    template_info.to_pickle(path.join(kilosort_folder, 'template_info.df'))

    return template_info


def generate_template_info_from_spike_info(spike_info, kilosort_folder, sampling_freq):

    clean_templates = np.unique(spike_info[ct.TEMPLATE_AFTER_SORTING].values)
    spike_times = spike_info[ct.TIMES].max()
    total_time = np.max(spike_times) / sampling_freq

    try:
        template_positions = np.load(path.join(kilosort_folder, 'weighted_template_positions.npy'))
    except:
        template_positions = np.zeros((len(clean_templates), 2))

    template_info = pd.DataFrame(columns=['template number', 'spikes in template', 'type', 'number of spikes',
                                          'firing rate', 'position X', 'position Y'])

    for clean_template_index in np.arange(len(clean_templates)):
        template_index = clean_templates[clean_template_index]
        type = spike_info[spike_info[ct.TEMPLATE_AFTER_SORTING] == template_index].iloc[0][ct.TYPE_AFTER_SORTING]

        if type != ct.types[0]:
            spikes_in_template = spike_info[ct.ORIGINAL_INDEX][spike_info[ct.TEMPLATE_AFTER_SORTING] == template_index].values
            number = len(spikes_in_template)
            rate = number / total_time

            template_info = template_info.append({'template number': template_index,
                                                 'spikes in template': spikes_in_template,
                                                  'type': type,
                                                  'number of spikes': number,
                                                  'firing rate': rate,
                                                  'position X': template_positions[clean_template_index, 0],
                                                  'position Y': template_positions[clean_template_index, 1]},
                                                 ignore_index=True)

    template_info.to_pickle(path.join(kilosort_folder, 'template_info.df'))

    return template_info


def generate_template_info_dataframe_after_manual_sorting(kilosort_folder):
    sorted_spike_templates = np.load(path.join(kilosort_folder, 'sorted_spike_templates.npy'))

    template_markings = np.load(path.join(kilosort_folder, 'template_marking.npy'))

    before_to_after_sorting_templates = np.load(path.join(kilosort_folder, 'before_to_after_sorting_templates.npy')).item()

    template_info = pd.DataFrame(columns=['template number', 'clean spikes in template', 'type'])

    i = 0
    spike_template = sorted_spike_templates[i]
    spike_template_before_sorting = \
        list(before_to_after_sorting_templates.keys())[
            list(before_to_after_sorting_templates.values()).index(spike_template)]
    type = template_markings[spike_template_before_sorting]

    template_info = template_info.append({'template number': spike_template,
                                          'clean spikes in template': [i],
                                          'type': type}, ignore_index=True)

    for i in np.arange(1, len(sorted_spike_templates)):
        spike_template = sorted_spike_templates[i]
        spike_template_before_sorting = \
        list(before_to_after_sorting_templates.keys())[list(before_to_after_sorting_templates.values()).index(spike_template)]
        type = template_markings[spike_template_before_sorting]

        if not np.any(list(template_info['template number'].isin([spike_template]))):
            template_info = template_info.append({'template number': spike_template,
                                                 'clean spikes in template': [i],
                                                  'type': type}, ignore_index=True)
        else:
            index = template_info['clean spikes in template'][template_info['template number']==spike_template].index
            index = np.int32(index)[0]
            template_info.loc[index, 'clean spikes in template'].append(i)

        if i % 100000 == 0:
            print('Done spikes: '+str(i)+' of '+str(len(sorted_spike_templates)))

    template_info.to_pickle(path.join(kilosort_folder, 'template_info.df'))

    return template_info


def _get_all_spikes_of_type_from_template_info(single_type_dataframe):
    spikes = np.empty(0).astype(np.int32)
    for index, row in single_type_dataframe.iterrows():
        new_spikes = np.array(list(row['clean spikes in template']))
        spikes = np.concatenate((spikes, new_spikes))

    return spikes


def generate_template_statistics(kilosort_folder):
    template_info = pd.read_pickle(path.join(kilosort_folder, 'template_info.df'))
    sorted_spike_templates = np.load(path.join(kilosort_folder, 'sorted_spike_templates.npy'))

    number_of_spikes = len(sorted_spike_templates)

    t1 = template_info[template_info['type'] == 1]
    print('Number of Single Unit templates  = ' + str(len(t1)))
    s1 = _get_all_spikes_of_type_from_template_info(t1)
    print('Number of spikes in SU = ' + str(len(s1)) + ' -> ' + str(100 * np.round(len(s1) / number_of_spikes, 2)) + '%')

    t2 = template_info[template_info['type'] == 2]
    print('Number of Contaminated Single Unit templates  = ' + str(len(t2)))
    s2 = _get_all_spikes_of_type_from_template_info(t2)
    print('Number of spikes in CSU = ' + str(len(s2)) + ' -> ' + str(100 * np.round(len(s2) / number_of_spikes, 2)) + '%')

    t3 = template_info[template_info['type'] == 3]
    print('Number of Putative Single Unit templates  = ' + str(len(t3)))
    s3 = _get_all_spikes_of_type_from_template_info(t3)
    print('Number of spikes in PSU = ' + str(len(s3)) + ' -> ' + str(100 * np.round(len(s3) / number_of_spikes, 2)) + '%')

    t4 = template_info[template_info['type'] == 4]
    print('Number of Multi Unit templates  = ' + str(len(t4)))
    s4 = _get_all_spikes_of_type_from_template_info(t4)
    print('Number of spikes in MU = ' + str(len(s4)) + ' -> ' + str(100 * np.round(len(s4) / number_of_spikes, 2)) + '%')

    print('Number of all types of Single Unit templates  = ' + str(len(t1) + len(t2) + len(t3)))
    print('Number of spikes in all single unit templates = ' + str(len(s1) + len(s2) + len(s3)) + ' -> '
          + str(100 * np.round((len(s1) + len(s2) + len(s3)) / number_of_spikes, 2)) + '%')


def find_large_mua_templates(kilosort_folder, number_of_spikes_in_large_mua_templates=10000):
    templates_of_spikes = np.load(path.join(kilosort_folder, 'spike_templates.npy'))
    template_markings = get_template_marking(kilosort_folder)
    mua_templates = np.squeeze(np.argwhere(template_markings == 4))

    size_of_mua_templates = []
    large_mua_templates = []
    number_of_spikes_in_large_mua_templates = number_of_spikes_in_large_mua_templates
    for mua_template in mua_templates:
        mua_spikes = np.argwhere(np.in1d(templates_of_spikes, mua_template) > 0)
        size_of_mua_templates.append(len(mua_spikes))
        if len(mua_spikes) >= number_of_spikes_in_large_mua_templates:
            large_mua_templates.append(mua_template)

    return large_mua_templates


def t_sne_each_one_of_the_large_mua_templates_by_itself(kilosort_folder, tsne_folder, barnes_hut_exe_dir,
                                                        number_of_spikes_in_large_mua_templates=10000,
                                                        num_dims=2, perplexity=100, theta=0.2, iterations=3000,
                                                        random_seed=1, verbose=3):

    large_mua_templates = \
        find_large_mua_templates(kilosort_folder,
                                 number_of_spikes_in_large_mua_templates=number_of_spikes_in_large_mua_templates)

    templates_of_spikes = np.load(path.join(kilosort_folder, 'spike_templates.npy'))
    for mua_template in large_mua_templates[15:]:
        print('DOING TEMPLATE NUMBER {}, {} OUT OF {}'.format(mua_template,
                                                              np.argwhere(large_mua_templates == mua_template),
                                                              len(large_mua_templates)))

        tsne_folder_single_template = path.join(tsne_folder, 'template_{}'.format(mua_template))
        os.mkdir(tsne_folder_single_template)

        mua_spikes = np.argwhere(np.in1d(templates_of_spikes, mua_template) > 0)
        np.save(path.join(tsne_folder_single_template, ct.INDICES_OF_SPIKES_USED_FILENAME), mua_spikes)

        template_features_matrix = \
            calculate_pcs_features_matrix_for_tsne(kilosort_folder, tsne_folder_single_template,
                                                   spikes_used_with_original_indexing=mua_spikes)
        num_dims = num_dims
        perplexity = perplexity
        theta = theta
        iterations = iterations
        random_seed = random_seed
        verbose = verbose

        tsne.t_sne(template_features_matrix, files_dir=tsne_folder_single_template,
                   exe_dir=barnes_hut_exe_dir,
                   num_dims=num_dims, perplexity=perplexity,
                   theta=theta, iterations=iterations, random_seed=random_seed, verbose=verbose)
        generate_spike_info_from_full_tsne(kilosort_folder=kilosort_folder, tsne_folder=tsne_folder_single_template)


def load_spike_info_of_template(tsne_folder, x):
    tsne_folder_single_template = path.join(tsne_folder, 'template_{}'.format(x))
    return np.load(path.join(tsne_folder_single_template, 'spike_info.df'))

